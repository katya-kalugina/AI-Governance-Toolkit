# AI Governance Toolkit

A collection of computational models and decision-support tools designed to operationalize Responsible AI governance. This toolkit bridges the gap between high-level legal requirements (EU AI Act, GDPR) and technical implementation.

---

### [Balanced AI Governance Model](https://ai-governance-toolkit-rgcqpsvbvnfywrrmfa6tv6.streamlit.app)
A socio-technical framework for analyzing the trade-offs between **Technical Quality** (Art. 15 AI Act) and **Risk Mitigation**.
- **Scope:** Accuracy, Reliability, and Robustness as prerequisites for ethical AI.

### [AI System Classifier](https://ai-act-compliance-navigator-g7js7fwafmpct3dwk4qtjv.streamlit.app/)
A deterministic logic tree for classifying AI systems according to the legal criteria of the EU AI Act (Regulation (EU) 2024/1689).
- **Functionality:** Navigates Prohibited Practices (Art. 5), High-Risk AI (Art. 6 & Annex III), Transparency (Art. 50) and GPAI systemic risk thresholds.

### [AI Role Navigator](https://ai-role-navigator-zjcqute523oxsv6hicsnrj.streamlit.app/)
An interactive assessor for determining the legal status and obligations of operators within the AI lifecycle.
- **Roles:** Identifies status as Provider, Deployer, Importer, or Distributor.

### [AI Risk Assessment Calculator](https://ai-risk-calculator-zjcqute523oxsv6hicsnrj.streamlit.app/)
A quantitative scoring engine based on the EDPB 2025 guidelines and the FRASP protocol.
- **Methodology:** Deterministic evaluation of Probability (7 factors) and Severity (11 dimensions).
- **Compliance:** Automated "Stopper Rules" for absolute rights protection and real-time risk heatmap generation.


---
*Developed by Ekaterina Kalugina. Part of ongoing research into Socio-Technical AI Governance and Legal Engineering.*
